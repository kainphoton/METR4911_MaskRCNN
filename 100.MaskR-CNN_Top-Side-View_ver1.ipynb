{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Modules and setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hai\\Documents\\UQ\\UQ 2022 - Sixth Year\\METR4911_ML_Python\\Object_Detection_Tutorial_YouTube\\TFODCourse\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco_labels.txt, Labels for fruit/vegetable (6 labels) \n",
    "labels = {0: \"Person\", 51: \"Banana\", 52: \"Apple\", 54: \"Orange\", 55: \"Broccoli\", 56: \"Carrot\"}\n",
    "\n",
    "# Color in BGR in CV2 not RGB, match color with object's color\n",
    "colors = {\"Person\": (179,179,255), \"Banana\": (53, 225,255), \"Apple\": (0,8,255), \n",
    "         \"Carrot\": (33,145,237), \"Orange\": (0,126,255), \"Broccoli\": (0,255,74)}\n",
    "\n",
    "# Input Resize Image\n",
    "img_width, img_height  = (640, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Mask RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: cv_dnn\\mask_rcnn_inception_v2_coco_2018_01_28\\frozen_inference_graph.pb\n",
      "Config: cv_dnn\\mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Get file path of weights(.pb) and config (.pbtxt)\n",
    "frozen_pb = os.path.join(\"cv_dnn\", \"mask_rcnn_inception_v2_coco_2018_01_28\", \"frozen_inference_graph.pb\")\n",
    "pb_txt = os.path.join(\"cv_dnn\", \"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\")\n",
    "\n",
    "print(\"Weights:\", frozen_pb)\n",
    "print(\"Config:\",pb_txt)\n",
    "\n",
    "# Load the weights and the config of Mask RCNN\n",
    "net = cv2.dnn.readNetFromTensorflow(frozen_pb, pb_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Object Detection and Mask Segmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_mask(img):\n",
    "    height, width, _ = img.shape  # (row, column)\n",
    "    \n",
    "    ########################### Generate random colors and create black image ###########################\n",
    "    black_image = np.zeros((height, width, 3), np.uint8)\n",
    "    \n",
    "    ########################### Detect objects ###########################\n",
    "    blob = cv2.dnn.blobFromImage(img, swapRB=True)  # Get blob of input image\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # boxes.shape (1,1,100,7),  mask.shape (100,90,15,15)\n",
    "    boxes, masks = net.forward([\"detection_out_final\", \"detection_masks\"])  # Actual prediction (takes time)\n",
    "    detection_count = boxes.shape[2]  # number of objects detected, 100 is the limit\n",
    "    \n",
    "    ############################ For each objects detected, draw box and mask ###########################\n",
    "    for i in range(detection_count):\n",
    "        # box [0,label,confidence,x1,y1,x2,y2] coods are normalised to 0-1 so multiply \n",
    "        #     the coods with image's width and height\n",
    "        box = boxes[0, 0, i]\n",
    "        class_id = int(box[1])  # Label/Class number, refer to coco_labels.txt\n",
    "        score = box[2]          # Confidence percentage\n",
    "        \n",
    "        # If score below (is part of label) or not part of labels want to detect skip\n",
    "        if class_id not in labels or score < 0.5:\n",
    "            continue\n",
    "\n",
    "        color = colors[labels[class_id]] # Color of object, defined in section 0\n",
    "        \n",
    "        ############################ Get Box Coordinates and Draw Box ############################\n",
    "        x = int(box[3] * width)    # Top left\n",
    "        y = int(box[4] * height)   # Top left\n",
    "        x2 = int(box[5] * width)   # Bottom right\n",
    "        y2 = int(box[6] * height)  # Bottom right\n",
    "        cv2.rectangle(img, (x,y), (x2,y2), (int(color[0]), int(color[1]), int(color[2])) , 2) # Draw rectangle box\n",
    "\n",
    "        ############################ Get the mask ############################\n",
    "        roi = black_image[y: y2, x: x2]\n",
    "        roi_height, roi_width, _ = roi.shape\n",
    "        mask = masks[i, int(class_id)]  # mask.shape -> (15, 15)\n",
    "        mask = cv2.resize(mask, (roi_width, roi_height))\n",
    "        \n",
    "        # 0.5 is threshold of confidence score of each pixel? so over 0.5 becomes 255 and 0 otherwise\n",
    "        _, mask = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        ############################ Get Mask Coordinates ############################\n",
    "        # Extract boundary of object\n",
    "        contours, _ = cv2.findContours(np.array(mask, np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)         \n",
    "        \n",
    "        ############################ Draw and Fill Polygons ############################\n",
    "        for cnt in contours:\n",
    "            cv2.fillPoly(roi, [cnt], (int(color[0]), int(color[1]), int(color[2])))\n",
    "    \n",
    "    ############################ Display output image on computer ############################\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    cv2.imshow(\"Black Image\", black_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have function for drawing rectangle box and add text label in, (x1,y1,x2,y2,color,label,padding,confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Detect Static Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_test_train_images_xml\\Fruit_Vegetable_15-July-22\\collectedimages\\banana\\banana.d8fbcaf6-03f4-11ed-a1f3-95c0acd580f9.jpg\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "img_file = \"banana.d8fbcaf6-03f4-11ed-a1f3-95c0acd580f9.jpg\"\n",
    "img_path = os.path.join(\"old_test_train_images_xml\", \"Fruit_Vegetable_15-July-22\", \"collectedimages\", \"banana\", img_file)\n",
    "\n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 640\n",
      "Height: 480\n"
     ]
    }
   ],
   "source": [
    "# Read image and resize image to (640, 480) or other dimensions\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (img_width,img_height), interpolation = cv2.INTER_AREA)\n",
    "height, width, _ = img.shape\n",
    "\n",
    "# 0 = open until any key is pressed, then close, any other number, in milliseconds, opens window in that duration\n",
    "cv2.imshow(\"Image ({},{})\".format(width, height), img)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Width:\", width)\n",
    "print(\"Height:\", height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Static Image Only\n",
    "object_detection_mask(img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Real Time Video Object Detection and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    object_detection_mask(frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debuggin, or webcam still on when having errors\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 179, 255)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
